# Dá»± Ä‘oÃ¡n GiÃ¡ NhÃ  - AIO2025 Project 5.1

Há»‡ thá»‘ng dá»± Ä‘oÃ¡n giÃ¡ nhÃ  sá»­ dá»¥ng XGBoost, FastAPI, Streamlit vÃ  MLflow (Ames Housing Dataset).

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
AIO2025_Project5.1_HousesPricing/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                                    # Dá»¯ liá»‡u gá»‘c
â”‚       â””â”€â”€ train-house-prices-advanced-regression-techniques.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                                    # FastAPI application
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                            # FastAPI app
â”‚   â”‚   â”œâ”€â”€ models.py                          # Pydantic models
â”‚   â”‚   â”œâ”€â”€ inference.py                       # Inference logic & CLI
â”‚   â”‚   â”œâ”€â”€ run_api.py                         # Script cháº¡y API server
â”‚   â”‚   â””â”€â”€ test_api.py                        # Test script cho API
â”‚   â”œâ”€â”€ processing/                             # Xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ transformers.py                     # Custom transformers
â”‚   â”‚   â””â”€â”€ data_processing.py                  # Preprocessing pipeline
â”‚   â”œâ”€â”€ e_featuring/                           # Feature engineering
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_featuring.py                  # Domain-specific features
â”‚   â”œâ”€â”€ training/                              # Training model
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ pipeline.py                        # Training pipeline
â”‚   â”‚   â””â”€â”€ train_model.py                     # Training script
â”‚   â”œâ”€â”€ configs/
â”‚   â”‚   â””â”€â”€ best_model_config.json             # Cáº¥u hÃ¬nh model tá»‘t nháº¥t
â”‚   â””â”€â”€ models/                                # Models Ä‘Ã£ train (auto-generated)
â”‚       â”œâ”€â”€ best_pipeline.joblib              # Pipeline hoÃ n chá»‰nh
â”‚       â””â”€â”€ feature_pipeline.joblib           # Feature pipeline
â”œâ”€â”€ deployments/
â”‚   â”œâ”€â”€ api/                                   # API deployment
â”‚   â”‚   â”œâ”€â”€ docker-compose.yaml                # Docker Compose for API
â”‚   â”‚   â””â”€â”€ Dockerfile                        # Dockerfile for API
â”‚   â””â”€â”€ mlflow/
â”‚       â””â”€â”€ docker-compose.yaml                # MLflow tracking server
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ house_price_analysis_mlflow.ipynb      # Jupyter notebook experiments
â”œâ”€â”€ train.py                                   # Script training chÃ­nh (root)
â”œâ”€â”€ requirements.txt                           # Dependencies
â””â”€â”€ README.md                                  # File nÃ y
```

## ğŸš€ Quick Start

### PhÆ°Æ¡ng Ã¡n A: Cháº¡y nhanh báº±ng Docker Compose (khuyáº¿n nghá»‹)

```bash
python train.py               # náº¿u chÆ°a cÃ³ model
cd deployments/api
docker compose up -d --build
```

Truy cáº­p:
- API: http://localhost:8000 (Docs: http://localhost:8000/docs)
- Frontend: http://localhost:8501
- MLflow: http://localhost:5555

### PhÆ°Æ¡ng Ã¡n B: Cháº¡y local (dev)

```bash
pip install -r requirements.txt
python train.py               # náº¿u chÆ°a cÃ³ model
python src/api/run_api.py     # cháº¡y API táº¡i 8000
streamlit run src/frontend/app.py
```

## ğŸ“Š Káº¿t quáº£

### Performance metrics

Model Ä‘Æ°á»£c train vá»›i cáº¥u hÃ¬nh tá»« `src/configs/best_model_config.json`:

- **CV RMSE**: 25259.42 Â± 3479.64
- **Test RMSE**: 24608.89
- **Test RÂ²**: 0.9210

### Output files

Sau khi training, cÃ¡c files sáº½ Ä‘Æ°á»£c táº¡o trong `src/models/`:

- `best_pipeline.joblib` - Pipeline hoÃ n chá»‰nh (features + model)
- `feature_pipeline.joblib` - Feature engineering pipeline

## ğŸ” MLflow

Má»Ÿ MLflow UI táº¡i `http://localhost:5555` Ä‘á»ƒ xem metrics, params vÃ  artifacts (khi cháº¡y báº±ng compose Ä‘Ã£ cÃ³ sáºµn).

### ThÃ´ng tin Ä‘Æ°á»£c track

- **Hyperparameters**: learning_rate, max_depth, subsample, ...
- **Performance metrics**: CV RMSE, CV RÂ², Test RMSE, Test RÂ²
- **Model artifacts**: Complete trained pipeline
- **Configuration**: Feature engineering vÃ  preprocessing settings

## ğŸ—ï¸ Pipeline

### 1. Data Processing (`src/processing/`)

**Custom Transformers:**
- `OrdinalMapper` - Map categorical variables sang numeric
- `MissingnessIndicator` - Táº¡o indicators cho missing values
- `RarePooler` - Gá»™p rare categories thÃ nh 'Other'
- `TargetEncoderTransformer` - Target encoding vá»›i smoothing
- `FiniteCleaner` - Convert infinite values thÃ nh NaN
- `DropAllNaNColumns` - Loáº¡i bá» columns toÃ n NaN

**Preprocessing:**
- Ordinal encoding cho 20 ordinal features
- Missing value imputation (categorical: most_frequent, numerical: median)
- One-hot encoding cho categorical features
- Quantile transformation cho continuous features

### 2. Feature Engineering (`src/e_featuring/`)

**Domain features (18 features):**
- `TotalSF` - Total square footage
- `TotalBath` - Total bathrooms
- `HouseAge`, `RemodAge`, `GarageAge` - Age features
- `IsRemodeled`, `Has2ndFlr` - Binary features
- `TotalPorchSF` - Total porch area
- `BathPerBedroom`, `RoomsPerArea`, `LotAreaRatio` - Ratio features
- `MoSold_sin`, `MoSold_cos` - Seasonal features
- `Neighborhood_BldgType` - Interaction features
- `Ln_TotalSF` - Log transformation
- `IQ_OQ_GrLiv`, `IQ_OQ_TotalSF` - Quality-area interactions
- `LotArea_clip` - Winsorization

### 3. Model Training (`src/training/`)

**Best Model:** XGBoost Regressor vá»›i hyperparameters tá»« config

**Training Process:**
1. Load data vÃ  split train/test (80/20)
2. Build feature pipeline vá»›i domain features
3. Train XGBoost vá»›i best hyperparameters
4. Cross-validation (5-fold)
5. Test set evaluation
6. LÆ°u pipeline vÃ  artifacts vÃ o MLflow

## ğŸ”„ Quy trÃ¬nh

Raw data â†’ Preprocessing â†’ Feature Engineering â†’ Training (MLflow) â†’ Evaluation â†’ Save pipeline (`src/models/`)

## ğŸ¯ Sá»­ dá»¥ng Model

### Inference qua API

**Single prediction:**
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"OverallQual": 7, "GrLivArea": 1710, "YearBuilt": 2003}'
```

**Batch prediction:**
```bash
curl -X POST "http://localhost:8000/predict/batch" \
  -H "Content-Type: application/json" \
  -d '{"houses": [{...}, {...}]}'
```

**Python client:**
```python
import requests

response = requests.post(
    "http://localhost:8000/predict",
    json={"OverallQual": 7, "GrLivArea": 1710, "YearBuilt": 2003}
)
print(response.json())
```

Chi tiáº¿t tham sá»‘/response xem táº¡i `src/api/README.md`.

### Inference qua CLI

```bash
python src/api/inference.py data/raw/test_data.csv --output predictions.csv
```

### Programmatic usage

```python
import joblib
import pandas as pd

# Load trained pipeline
pipeline = joblib.load('src/models/best_pipeline.joblib')

# Predict
new_data = pd.read_csv('new_houses.csv')
predictions = pipeline.predict(new_data)
print(f"Predicted prices: {predictions}")
```

## ğŸ“š Tech stack

- FastAPI (API), Streamlit (UI), XGBoost + scikit-learn (ML), MLflow (tracking)

## ğŸ“ Model Performance

- **Dataset**: Ames Housing (1460 samples, 80 features)
- **Algorithm**: XGBoost Regressor
- **Evaluation**: 5-fold cross-validation
- **Best RMSE**: ~24609
- **Best RÂ²**: ~0.92

## ğŸš§ TÆ°Æ¡ng lai

- [x] API FastAPI, [x] Batch inference, [x] Streamlit UI
- [ ] Model versioning, [ ] Monitoring/alerts

## ğŸ“ Notes

- Raw data: Giá»¯ nguyÃªn trong `data/raw/`
- Trained models: LÆ°u trong `src/models/` (khÃ´ng commit lÃªn Git)
- MLflow data: LÆ°u trong `deployments/mlflow/` (khÃ´ng commit lÃªn Git)
- API: Cháº¡y trÃªn port 8000, cÃ³ thá»ƒ truy cáº­p qua Docker hoáº·c local
- Intermediate data: **KhÃ´ng lÆ°u** - chá»‰ dÃ¹ng pipeline Ä‘á»ƒ transform

## ğŸ”§ Deployment

### Triá»ƒn khai

```bash
# Docker Compose (khuyáº¿n nghá»‹)
cd deployments/api && docker compose up -d --build

# Local development
pip install -r requirements.txt
python src/api/run_api.py
```

### Test API

```bash
# After starting API
python src/api/test_api.py
```

### Truy cáº­p dá»‹ch vá»¥

- API: http://localhost:8000 (Docs: /docs)
- Frontend: http://localhost:8501
- MLflow: http://localhost:5555

## ğŸ“„ License

Project cho AIO2025 - Project 5.1
